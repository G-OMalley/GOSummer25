import requests
import pandas as pd
import os
import time
from datetime import datetime, timedelta
from dotenv import load_dotenv

# --- Configuration ---
load_dotenv() # Load environment variables from .env file
USERNAME = os.getenv("PLATTS_USERNAME")
PASSWORD = os.getenv("PLATTS_PASSWORD")

# API Endpoints
AUTH_URL = "https://api.ci.spglobal.com/auth/api"
MARKET_DATA_HISTORY_URL = "https://api.ci.spglobal.com/market-data/v3/value/history/symbol" 

# Input File Configuration (from the previous script)
INPUT_SYMBOLS_FOLDER = "INFO"
INPUT_SYMBOLS_FILE = "PlattsSymbols.csv" # This file should be generated by the symbol fetching script
INPUT_CSV_FULL_PATH = os.path.join(INPUT_SYMBOLS_FOLDER, INPUT_SYMBOLS_FILE)

# Historical Data Fetching Configuration
BATES_TO_RETRIEVE_HISTORY = "C,U,L,H,O" # Fetching Close, Index, Low, High, Open (Uppercase for the filter)

# Output Configuration
OUTPUT_HISTORICAL_DATA_FILE = "selected_historical_prices.csv"

HISTORY_PAGE_SIZE = 1000 
TODAY_FOR_CALCULATION = datetime(2025, 5, 25)

def get_access_token(username, password):
    """Authenticates and retrieves an access token."""
    if not username or not password:
        print("ERROR: Username or Password not found in .env file. Please ensure PLATTS_USERNAME and PLATTS_PASSWORD are set.")
        return None
    headers = {"Content-Type": "application/x-www-form-urlencoded"}
    payload = {"username": username, "password": password}
    print("Attempting to obtain access token...")
    try:
        response = requests.post(AUTH_URL, headers=headers, data=payload, timeout=30)
        response.raise_for_status()  
        token_data = response.json()
        print("Successfully obtained access token.")
        return token_data.get("access_token")
    except requests.exceptions.HTTPError as http_err:
        print(f"Http Error during authentication: {http_err}")
        if http_err.response is not None:
            print(f"Response status: {http_err.response.status_code}")
            print(f"Response content: {http_err.response.content.decode()}")
    except Exception as e:
        print(f"An unexpected error occurred during authentication: {e}")
    return None

def load_and_select_symbols(symbols_file_path):
    """Loads symbols from CSV, allows user selection."""
    try:
        df_symbols = pd.read_csv(symbols_file_path)
        if 'description' not in df_symbols.columns or 'symbol' not in df_symbols.columns:
            print(f"Error: '{symbols_file_path}' must contain 'symbol' and 'description' columns.")
            return None
    except FileNotFoundError:
        print(f"Error: Symbols file not found at '{symbols_file_path}'. Please run the symbol fetching script first.")
        return None
    except Exception as e:
        print(f"Error reading symbols file: {e}")
        return None

    df_symbols['description'] = df_symbols['description'].astype(str)
    prelim_keyword = "prelim" 
    initial_count = len(df_symbols)
    df_symbols = df_symbols[~df_symbols['description'].str.lower().str.contains(prelim_keyword, na=False)]
    if len(df_symbols) < initial_count: 
        print(f"Note: Excluded {initial_count - len(df_symbols)} symbols containing '{prelim_keyword}' from the loaded file.")

    unique_descriptions = sorted(df_symbols['description'].unique())
    if not unique_descriptions:
        print("No unique descriptions found in the symbols file after filtering. Exiting.")
        return None

    print("\nAvailable descriptions for historical data (non-Prelim, FDt Com based on previous script's filtering):")
    for i, desc in enumerate(unique_descriptions):
        print(f"{i+1}. {desc}")
    
    while True:
        selected_indices_str = input(f"Enter the numbers of the descriptions you want to process (comma-separated, e.g., 1,3,5), or type 'all': ")
        if selected_indices_str.strip().lower() == 'all':
            selected_descriptions = unique_descriptions
            print("Processing all available symbols.")
            break
        else:
            try:
                selected_indices = [int(x.strip()) - 1 for x in selected_indices_str.split(',')]
                if all(0 <= i < len(unique_descriptions) for i in selected_indices):
                    selected_descriptions = [unique_descriptions[i] for i in selected_indices]
                    if not selected_descriptions: 
                        print("No descriptions selected. Please try again.")
                        continue
                    break
                else:
                    print("Invalid selection: One or more numbers are out of range.")
            except ValueError:
                print("Invalid input. Please enter numbers separated by commas or 'all'.")
    
    if not selected_descriptions:
        print("No valid descriptions selected. Exiting.")
        return None

    print(f"\nYou selected: {', '.join(selected_descriptions)}")
    df_selected_symbols = df_symbols[df_symbols['description'].isin(selected_descriptions)]
    return df_selected_symbols

def get_date_range_from_user(today_date):
    """Prompts user for start and end dates, defaulting to last 45 days."""
    default_end_date = today_date 
    default_start_date = today_date - timedelta(days=45) 
    print(f"\nDefault date range is from {default_start_date.strftime('%Y-%m-%d')} to {default_end_date.strftime('%Y-%m-%d')}.")
    while True:
        start_date_str = input(f"Enter start date (YYYY-MM-DD) [default: {default_start_date.strftime('%Y-%m-%d')}]: ") or default_start_date.strftime('%Y-%m-%d')
        end_date_str = input(f"Enter end date (YYYY-MM-DD) [default: {default_end_date.strftime('%Y-%m-%d')}]: ") or default_end_date.strftime('%Y-%m-%d')
        try:
            start_date_obj = datetime.strptime(start_date_str, "%Y-%m-%d")
            end_date_obj = datetime.strptime(end_date_str, "%Y-%m-%d")
            if start_date_obj > end_date_obj:
                print("Start date cannot be after end date.")
            else:
                return start_date_str, end_date_str
        except ValueError:
            print("Invalid date format. Please use YYYY-MM-DD.")

def fetch_historical_data_for_symbols(token, symbols_df, start_date, end_date, bates_to_fetch):
    """Fetches historical data for a list of symbols."""
    all_historical_records = []
    for index, row in symbols_df.iterrows():
        symbol = row['symbol']
        description = row['description']
        print(f"\nFetching data for: {symbol} ({description})")
        bates_for_filter_parts = [f'bate:"{b.strip().upper()}"' for b in bates_to_fetch.split(',')] 
        bates_segment = " OR ".join(bates_for_filter_parts)
        custom_filter = (
            f'symbol IN ("{symbol}") AND ({bates_segment}) ' 
            f'AND assessDate>="{start_date}" AND assessDate<="{end_date}"'
        )
        params = {"Filter": custom_filter, "PageSize": HISTORY_PAGE_SIZE}
        current_page = 1
        total_pages = 1
        headers = {"Authorization": f"Bearer {token}", "Accept": "application/json"}
        print(f"  Using Filter: {custom_filter}")
        while current_page <= total_pages:
            params["Page"] = current_page
            try:
                response = requests.get(MARKET_DATA_HISTORY_URL, headers=headers, params=params, timeout=60)
                response.raise_for_status()
                data = response.json()
                results = data.get("results", [])
                if results:
                    if current_page == 1 and results: 
                        print(f"  DEBUG: First raw result object from API for symbol {symbol}: {results[0]}")
                    for record in results: 
                        record['description_from_input'] = description 
                    all_historical_records.extend(results)
                    print(f"  Fetched {len(results)} records on page {current_page}.")
                else:
                    if current_page == 1: 
                         print(f"  No data found for {symbol} in this date range on page 1.")
                metadata = data.get("metadata", {})
                api_total_pages = metadata.get('totalPages', metadata.get('total_pages'))
                if api_total_pages is not None:
                    total_pages = api_total_pages
                elif current_page == 1 and not results: 
                    total_pages = 0 
                if current_page >= total_pages or not results: 
                    break
                current_page += 1
                time.sleep(0.1) 
            except requests.exceptions.HTTPError as http_err:
                print(f"  HTTP Error fetching history for {symbol} (page {current_page}): {http_err}")
                if http_err.response is not None:
                    print(f"  Response status: {http_err.response.status_code}")
                    print(f"  Response content: {http_err.response.content.decode()}")
                break 
            except Exception as e:
                print(f"  General Error fetching history for {symbol} (page {current_page}): {e}")
                break 
        time.sleep(0.2) 
    return all_historical_records

def process_and_save_data(historical_records, output_file):
    """Processes fetched historical data and saves it to CSV."""
    if not historical_records:
        print("\nNo historical data to process or save.")
        return

    flat_bate_entries = []
    for api_result_object in historical_records: 
        our_symbol_from_input = api_result_object.get('symbol') # Symbol added by fetch_historical_data_for_symbols
        our_description = api_result_object.get('description_from_input')
        
        # The API's own symbol for this record (should match our_symbol_from_input)
        api_native_symbol = api_result_object.get('symbol') 

        # Extract currency and uom from 'referenceData' if present, as per Swagger example
        reference_data = api_result_object.get('referenceData', {})
        currency = reference_data.get('currency')
        uom = reference_data.get('uom')

        # The actual bate assessments are in a list under the 'data' key
        if 'data' in api_result_object and isinstance(api_result_object['data'], list):
            for bate_assessment_entry in api_result_object['data']:
                bate_code = bate_assessment_entry.get('bate')
                flat_record = {
                    'symbol': api_native_symbol, # Use the symbol from the API's main object for this result
                    'description': our_description, # Use our consistent description
                    'Date': bate_assessment_entry.get('assessDate'),
                    'bate': bate_code.upper() if bate_code else None, # Convert API's (likely lowercase) bate to UPPERCASE for pivot
                    'value': bate_assessment_entry.get('value'),
                    'currency': currency, 
                    'uom': uom
                }
                flat_bate_entries.append(flat_record)
        else:
            print(f"  WARNING: Expected 'data' key with a list of bates for symbol {api_native_symbol}, but not found or not a list. Record: {api_result_object}")

    if not flat_bate_entries:
        print("No bate entries could be extracted from the fetched historical data after processing. Nothing to save.")
        return

    df_flat = pd.DataFrame(flat_bate_entries)

    if df_flat.empty:
        print("DataFrame of flat bate entries is empty. Nothing to pivot or save.")
        return
        
    try:
        index_cols = ['symbol', 'description', 'Date']
        if 'currency' in df_flat.columns and df_flat['currency'].notna().any():
            index_cols.append('currency')
        if 'uom' in df_flat.columns and df_flat['uom'].notna().any():
            index_cols.append('uom')
        
        if 'bate' not in df_flat.columns:
            print("ERROR: 'bate' column is missing from the data prepared for pivoting. Cannot proceed.")
            print("Sample of df_flat head:")
            print(df_flat.head())
            return

        df_pivoted = df_flat.pivot_table(
            index=index_cols, 
            columns='bate', # This will now use UPPERCASE bate codes ('C', 'U', 'L', etc.)
            values='value'
        ).reset_index()
    except Exception as e:
        print(f"Error during pivoting data: {e}")
        print("DataFrame before pivot attempt (df_flat head):")
        print(df_flat.head())
        return

    if df_pivoted.empty:
        print("DataFrame is empty after pivoting. Nothing to save.")
        return
        
    def determine_primary_price(row):
        desc = row.get('description', '')
        # Bates are now column names like 'C', 'U' (uppercase) after pivot
        if isinstance(desc, str) and desc.lower().startswith('ice'):
            return row.get('C') # ICE uses Close (bate 'C')
        else:
            return row.get('U') # Non-ICE uses Index/Settle (bate 'U')
            
    if 'description' in df_pivoted.columns:
        df_pivoted['PrimaryPrice'] = df_pivoted.apply(determine_primary_price, axis=1)

    column_renames = {
        'L': 'Low(l)', 
        'H': 'High(h)',
        'C': 'Close(c)',
        'U': 'Index(u)',
        'O': 'Open(o)',
    }
    df_pivoted.rename(columns=column_renames, inplace=True)
    
    desired_columns = ['symbol', 'description', 'Date']
    if 'currency' in df_pivoted.columns: desired_columns.append('currency')
    if 'uom' in df_pivoted.columns: desired_columns.append('uom')
    desired_columns.extend(['Low(l)', 'High(h)', 'Open(o)', 'Close(c)', 'Index(u)', 'PrimaryPrice'])
    
    output_columns = [col for col in desired_columns if col in df_pivoted.columns]
    df_output = df_pivoted[output_columns]

    try:
        df_output.to_csv(output_file, index=False)
        print(f"\nSuccessfully saved historical data to {output_file}")
        print("\nSample of the final data:")
        print(df_output.head())
    except PermissionError:
        print(f"\nERROR: Permission denied when trying to save {output_file}.")
        print("Please ensure the file is not open in another program (e.g., Excel) and that you have write permissions to the directory.")
    except Exception as e:
        print(f"Error saving final data to CSV {output_file}: {e}")

def main():
    """Main function to drive the script."""
    if not USERNAME or not PASSWORD:
        print("ERROR: Credentials not loaded from .env file.")
        return

    access_token = get_access_token(USERNAME, PASSWORD)
    if not access_token:
        return

    df_selected_symbols = load_and_select_symbols(INPUT_CSV_FULL_PATH)
    if df_selected_symbols is None or df_selected_symbols.empty:
        return

    start_date, end_date = get_date_range_from_user(TODAY_FOR_CALCULATION)
    
    historical_data_raw_results = fetch_historical_data_for_symbols(
        access_token, 
        df_selected_symbols, 
        start_date, 
        end_date, 
        BATES_TO_RETRIEVE_HISTORY 
    )
    
    process_and_save_data(historical_data_raw_results, OUTPUT_HISTORICAL_DATA_FILE)

    print("\nScript finished.")

if __name__ == "__main__":
    main()